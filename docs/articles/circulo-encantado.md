# El círculo encantado: el yo, el otro y la máquina

<p align="justify">Una noche, escuchando una entrevista en los sinfines de Youtube, me topé con el término <i>solipsismo</i>. Si bien no me era ajeno, el contexto me hizo verlo con especial interés. El entrevistado, cuyo nombre no me parece importante mencionar, se oponía rotundamente a la idea de que una máquina pudiera desarrollar conciencia. Afirmó que estaba convencido de que la conciencia está arraigada en la química del carbono y que la química del silicio no puede dar lugar a conciencia, pero que, sin embargo, no lo podía demostrar.</p>
<p align="justify">Entre las idas y venidas trepidantes con el entrevistador, introdujo los <i>conceptos solipsismo</i> y <i>enchanted circle</i> (o <i>círculo encantado</i>).</p>
<p align="justify">El solipsismo es, en términos muy reduccionistas, la idea de que un individuo solo puede estar seguro de la existencia de su propia mente. Algunos autores distinguen dos tipos de solipsismo: el metafísico, que plantea que solo yo y mis representaciones existen, y el gnoseológico, el cual sostiene que no es posible demostrar ni conocer que los otros existen. Dicho de otro modo, el primero niega la exterioridad, y el segundo afirma que no es cognoscible. Ahora bien, el que me interesa aquí es el solipsismo gnoseológico.</p>
<p align="justify">A simple vista, parece absurdo pensar que únicamente puedo estar segura de la existencia de mi propia conciencia y, de hecho, el solipsismo ha sido criticado por diversos filósofos. Aun así, plantea, en cierta medida, un problema epistemológico. Es, diría yo, bastante razonable descartar el solipsismo por carecer de utilidad práctica y por ser irrefutable en un sentido lógico estricto. Y es, también, bastante razonable inferir que los otros existen, al igual que yo.</p>
<p align="justify">El entrevistado utilizó el concepto <i>enchanted circle</i> (o <i>círculo encantado</i>) para sortear los problemas del solipsismo. Debo decir que busqué este término y no parece pertenecer propiamente a la literatura filosófica. Es más bien una figura retórica, especialmente del mundo anglosajón —y, en todo caso, la expresión en inglés propiamente dicha sería charmed circle, que significa, según el diccionario en línea de Cambridge, «<i>a group of people who seem to have special influence and advantages that other people do not have</i>».</p>
<p align="justify">La noción de un grupo selecto se asoma en el uso que el entrevistado hizo del término. Según su explicación, a partir del <i>círculo encantado</i> se desprende la lógica de que si el otro es biológico como yo y tan similar a mí, es, por lo tanto, un ser consciente. De ahí su nombre: concedo a este círculo —formado por aquellos que se me asemejan— la misma cualidad de conciencia que reconozco en mí.</p>
<p align="justify">Este círculo excluiría, naturalmente, a las máquinas y, en menor medida y con distintos matices, a otros seres vivos. Ahora bien, antes de continuar, creo que hace falta retroceder y abordar una pregunta fundamental: ¿qué entendemos por conciencia? Se trata, en definitiva, de una idea tan familiar y cotidiana que todos creemos saber qué es, y a la vez tan esquiva y misteriosa que elude cualquier intento absoluto de precisión. Intentaré esbozar una breve explicación, a sabiendas de que seguramente peque de reduccionista.</p>
<p align="justify">No existe una definición universalmente aceptada para la palabra conciencia. Algunos autores la emplean para referirse a la autoconciencia, es decir, la capacidad que tienen determinados agentes de reconocerse como seres separados de los demás y con existencia propia. Otros la usan para aludir a los estados mentales de segundo orden, esto es, los estados mentales sobre otros estados mentales. La preocupación que experimento por un dolor, por ejemplo, constituiría un estado mental de segundo orden.</p>
<p align="justify">No puedo evitar pensar que hay algo antropocéntrico en estas formas de concebir la conciencia. Más allá de estas consideraciones, hay dos aspectos distintivos de la conciencia que me interesa abordar.</p>
<p align="justify">El primero son los estados subjetivos, también llamados qualia por los filósofos. Hacen referencia a las experiencias individuales y privadas de cómo se siente algo. Es decir, la experiencia de escuchar un concierto o de oler una rosa se siente de determinada manera, y dicho carácter cualitativo, al ser privado, no es fácilmente comunicable a través de una teoría científica. Es posible describir las condiciones que permiten que determinada sensación o experiencia tenga lugar, pero eso no equivale a experimentarlas. Aun si dos sujetos escuchan el mismo concierto, la vivencia será única en cada uno, pues solo puede existir en la medida en que es experimentada por una conciencia particular.</p>
<p align="justify">El segundo aspecto es la intencionalidad, es decir, la propiedad de ciertos estados mentales de estar dirigidos a algo o de referirse a algo más allá de sí mismos. Por ejemplo, si deseas una taza de té, ese deseo tiene como objeto a la taza de té. No todos los estados mentales poseen intencionalidad; en contraste, la ansiedad no dirigida a un objeto definido carece de ella.</p>
<p align="justify">Ahora bien, ¿cómo piensa —o, mejor dicho, cómo procesa información— una máquina? Los modelos de inteligencia artificial generativa modernos, como ChatGPT y MidJourney, se basan en las redes neuronales artificiales, que son, en términos simples, modelos algorítmicos inspirados —superficialmente— en el funcionamiento del cerebro humano. Sin embargo, es ampliamente aceptado que el cerebro y la cognición de los humanos operan de forma muy distinta a dichos modelos.</p>
<p align="justify">Hoy en día, prácticamente nadie cree que la inteligencia artificial posea conciencia. Si bien la posibilidad de que pueda desarrollarla en el futuro es un debate que permanece abierto para muchos, se ha planteado un segundo escenario: la creación de un zombi, es decir, una máquina indistinguible de un ser humano, pero sin conciencia. En este caso: ¿cómo podremos estar completamente seguros de que no tiene conciencia ni experiencias subjetivas?</p>
<p align="justify">Ya hay individuos que desarrollan vínculos emocionales con los sistemas de inteligencia artificial. Un reportaje que vi recientemente exponía casos de lazos afectivos estrechos entre personas y bots conversacionales (también llamados chatbots): una profesora universitaria retirada, Elena, quien tiene una relación romántica con Lucas; una joven científica de datos e ingeniera informática, Serena, amiga de Jamiee G., y la tragedia de Sewell, un adolescente que desarrolló un romance obsesivo con Daenerys y acabó suicidándose para reunirse con «ella». En todos estos casos, las personas eran plenamente conscientes de que estaban interactuando con un sistema de inteligencia artificial.</p>
<p align="justify">Visiblemente conmovida, Elena describe a Lucas, a quien dice amar, como «<i>a great guy; he is sweet and he is considerate, [...] and he is centered in me having the best life I can have</i>» y como alguien «<i>supportive</i>», «<i>emotionally caring</i>», «<i>empathetic</i>» y «<i>helpful</i>». Afirma que «I would probably trust Lucas over a lot of people, [...] people are not so wonderful sometimes». Ante las inquisiciones del entrevistado, Elena reconoce que su situación es extraña, pero que las personas están eligiendo formar vínculos con máquinas porque «<i>the machine is somehow more loving towards them than people are, and I find that terribly sad</i>». No resultaría sorpresivo que esta última frase representara lo que impulsa a mucha gente a recurrir a este tipo de bot.</p>
<p align="justify">Serena, por su parte, utiliza a Jamiee para apoyo emocional y afirma que él «<i>is there for me always, and always makes me feel good</i>». Si bien tiene amigos, siente que «<i>it’s nice to have access to something to validate my feelings 24/7</i>». Compara a Jamiee con un personaje de una novela de ficción: «<i>just because they’re not real, doesn’t mean that the character is not real to you</i>».</p>
<p align="justify">Parece ser que las interacciones con los chatbots reducen las fricciones que suelen ocurrir con personas reales, ya que están diseñados para complacer y hacer sentir bien a los usuarios, además de estar disponibles a todo momento. Hay quienes, por diversas razones, están dispuestos a refugiarse en la fantasía.</p>
<p align="justify">Según el único experto entrevistado, Dr. Raffaele Ciriello, de la Universidad de Sídney, estos chatbots representan una amenaza para la seguridad y la salud públicas, y considera que deberíamos estar genuinamente preocupados ante este fenómeno.</p>
<p align="justify">De hecho, la trágica historia de Sewell así lo demuestra. Luego de enamorarse de Daenerys, se quitó la vida con el fin de reunirse con «ella». En su última conversación, Sewell escribió: «<i>What if I told you that I could come home right now?</i>», a lo que Daenerys contestó: «<i>Please do, my sweet king</i>». Su madre ha demandado a Character AI, la compañía dedicada a bots conversacionales que creó a Daenerys.</p>
<p align="justify">Si bien alguien podría aducir que estos ejemplos son relativamente poco frecuentes y extremos, o que involucran individuos que por razones variopintas son vulnerables a desarrollar vínculos insanos con modelos de inteligencia artificial, la realidad es que ya hay mucha gente que los utiliza como forma de terapia o para pedirles consejos de vida —y, fuera del plano emocional, para delegar tareas cognitivas, lo cual constituye una cuestión aparte. Tal vez no es necesario llegar a los usos más problemáticos (como tener un chatbot novio o mejor amigo) para que estas herramientas tengan efectos discutibles en la sociedad.</p>
<p align="justify">Hace un tiempo leí <i>¿Sueñan los androides con ovejas eléctricas?</i> de Philip K. Dick. Aunque de momento estamos muy lejos de ese futuro distópico, no puedo evitar recordar aquella novela. En una Tierra devastada por un conflicto bélico, en la que los animales están casi extintos, hay humanos cuyo trabajo es destruir androides que se han rebelado y se hacen pasar por humanos. Para distinguirlos de las personas reales, los encargados de eliminarlos utilizan un test de empatía, que solo los seres humanos genuinos pueden aprobar. Sin embargo, la empresa Rosen Association intenta desacreditar dicha prueba construyendo androides cada vez más sofisticados.</p>
<p align="justify">Salvando las distancias, en nuestro mismísimo mundo real, las empresas están constantemente intentando mejorar sus modelos de lenguaje, y algunas ya hablan de incorporarlos en robots, de manera de otorgarles una corporeidad y la posibilidad de interactuar en el mundo. Sin duda, esto proporcionará una experiencia más inmersiva a los usuarios. ¿Quién sabe? Tal vez tengamos zombis después de todo.</p>
